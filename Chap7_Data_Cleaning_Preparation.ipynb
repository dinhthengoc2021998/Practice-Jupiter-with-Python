{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sys,csv,os,IPython,string,re\n",
    "from numpy import NaN as NA\n",
    "pd.options.display.max_rows=10\n",
    "pd.options.display.max_columns=10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.1Handling Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# None~NA and NaN is a data that doesn't exist or exist but wasn't be observed\n",
    "# Create a seires that has None(~NA) and np.NaN in value\n",
    "series=pd.Series(np.array([None,np.NaN,'thach','thach','ngoc','ngoc']),index=[x for x in range(0,6)])\n",
    "# condition to check series is null\n",
    "series.isnull()\n",
    "# Fill every NA value is string of this. Use the pd.fillna(values,inplace)\n",
    "series.fillna(value={i:str(x) for i,x in enumerate(series[series.isnull()])},inplace=True)\n",
    "type(series.loc[0])# check the type of NA value is string or not\n",
    "# Use dropna\n",
    "series.dropna(inplace=True,axis=0)# it's not change because we assign NA values into string at the previous code\n",
    "# Drop duplicate with keep unique value or false to del it \n",
    "series.drop_duplicates(inplace=True,keep='first')# keep use 'first','last' to take the position index or False to drop all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering Out Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     a    b    c     d\n",
      "0  1.0  6.5  3.0   NaN\n",
      "1  1.0  NaN  NaN   NaN\n",
      "2  1.0  NaN  NaN   NaN\n",
      "3  2.0  5.6  3.0   NaN\n",
      "4  NaN  NaN  NaN  10.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     a\n",
       "0  1.0\n",
       "1  1.0\n",
       "2  1.0\n",
       "3  2.0\n",
       "4  NaN"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a value with type is float\n",
    "series=pd.Series([NA,1.4,9,100,100,NA,None])# None will change to NaN because the type is float\n",
    "# drop every value is NA\n",
    "series.dropna(axis=0)\n",
    "# choose the location of series that  dont contain NA value\n",
    "series.loc[series.notnull()]\n",
    "# create a dataframe that has many NA value at columns and index\n",
    "data=pd.DataFrame([[1.,6.5,3.],[1.,NA,NA],[1,NA,NA],[2,5.6,3.]],columns=['a','b','c'],index=[0,1,2,3])\n",
    "#drop every row that contains any or all value is NA\n",
    "data.dropna(axis=0)# del row\n",
    "# use subset with the axis to choose the subset we need to consider to dropna\n",
    "data.dropna(axis=1,how='any',subset=[1,2,3])# drop every col that contain any or all value is NA\n",
    "data.dropna(how='any')# how='any' is drop every row or col that has at least one NA value\n",
    "data.dropna(axis=0,how='all',subset=['a','b'])# dropna in subset that have axis=0 with col=['a','b']\n",
    "# create a new columns named 'd' and index 4  with every value is NA except loc[4,'d']\n",
    "data.loc[4,'d']=10\n",
    "print(data)\n",
    "# in subset=[0,2,4][axis=1], where the columns has at least 2 non-NA value and drop every col has non-NA<2\n",
    "data.dropna(axis=1,subset=[0,2,4],how='any',thresh=2)# thresh is require the non_NA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling in Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.5000</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.3875</td>\n",
       "      <td>32.25</td>\n",
       "      <td>3.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.2750</td>\n",
       "      <td>61.50</td>\n",
       "      <td>5.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0500</td>\n",
       "      <td>120.00</td>\n",
       "      <td>10.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     a       b       c       d\n",
       "0  1.0  6.5000    3.00   1.500\n",
       "1  1.0  6.3875   32.25   3.625\n",
       "2  1.0  6.2750   61.50   5.750\n",
       "3  2.0     NaN     NaN     NaN\n",
       "4  2.0  6.0500  120.00  10.000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fill NA value at particular col with the particular value\n",
    "noNa_data=data.fillna({'b':data['b'].mean(),'c':120})\n",
    "# set the subset of dataframe is NA\n",
    "noNa_data.loc[1:3,['b','c']]=NA\n",
    "# use method is ffill by fill the nearest value by axis\n",
    "noNa_data.fillna(axis=1,method='ffill',limit=2)# fill the NA value as the beside value\n",
    "# use interpolate to fill NA value as a value that between the min and max \n",
    "#set the min value of d at first row\n",
    "noNa_data.loc[0,'d']=1.5\n",
    "# return every value that in between min and max\n",
    "noNa_data.interpolate(axis=0,limit=2)# limit 2 NA value can be replace at axis=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.2 Data Transformation\n",
    "### Removing Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key1</th>\n",
       "      <th>value</th>\n",
       "      <th>v1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>two</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>three</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    key1  value  v1\n",
       "0    one      1   0\n",
       "1    two      2   1\n",
       "6  three      3   6"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a df that have duplicate\n",
    "data=pd.DataFrame({'key1':['one','two']*3+['three','three'],'value':[1,2]*3+[3,3]})\n",
    "# Condition for duplicated value that have every value at every col is the same\n",
    "data.duplicated()\n",
    "# Show the set of unique value\n",
    "data[data.duplicated(keep='first')]\n",
    "# drop duplicated\n",
    "noDuplicated=data.drop_duplicates(keep='first')\n",
    "# choose the col to drop duplicated value\n",
    "data['v1']=range(8)# this is no duplicate because each value of col'v1' is different to remainder\n",
    "data.drop_duplicates(subset=['key1','value'],keep='first')# choose the subset to consider to drop duplicate if existed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming Data Using a Function or Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a df that have food and ounces\n",
    "data=pd.DataFrame({\n",
    "    'food':['bacon','pulled pork','bacon','Pastrami','corned beef',\n",
    "            'Bacon','pastrami','honey ham','nova lox'],\n",
    "    'ounces':[4,3,12,6,7.5,8,3,5,6]})\n",
    "meat_to_animal={\n",
    "    'bacon':'pig',\n",
    "    'pulled pork':'pig',\n",
    "    'pastrami':'cow',\n",
    "    'honey ham':'pig',\n",
    "    'nova lox':'salmon'}\n",
    "# convert every value in data['food'] to lower by using lambda x:x.lower()\n",
    "lower_food=data['food'].map(lambda x: x.lower())\n",
    "# Use map to create a new series with the input correspondence dict,list,..\n",
    "data['animal']=lower_food.map(arg=meat_to_animal,na_action=None)# arg is mappind correspondence\n",
    "#------------------------------------------------------------------\n",
    "# Another way to transform is create a list of 'animal' columns then assign it to 'animal' col\n",
    "food=data['food']\n",
    "data['animal']=[meat_to_animal[x.lower()] if x.lower() in meat_to_animal else None for x in food]\n",
    "# convert every null value to NA value\n",
    "data[data.isnull()]=NA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.DataFrame({'a':[10,-999,1000,1000,-999,2],'b':[10,-999,1000,1000,-999,2]})\n",
    "# use dict to enumerate the key-value to replace\n",
    "data.replace({-999:NA,1000:0})\n",
    "# use to list to put the correspondencee value \n",
    "data.replace([-999,1000],[NA,0])\n",
    "# replace in each series by convert the data['a'].replace to data['a']\n",
    "data['a']=data['a'].replace([-999,1000],[NA,0])\n",
    "# create  a list to replace\n",
    "replace_dict={-999:NA,1000:0}\n",
    "data['a']=data['a'].map(replace_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renaming Axis indexes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "str.upper\n",
    "data=pd.DataFrame(np.arange(12).reshape(3,4),\n",
    "                  index=['Ohio','Colorado','New York'],\n",
    "                  columns=['one','two','three','four'])\n",
    "# use map correspondence on data.index\n",
    "data.index=data.index.map(lambda x: x[:4].upper())# x[:4] is a short-for written\n",
    "# Use data.rename\n",
    "data.rename(columns=str.upper,index=str.title,inplace=True)\n",
    "# Use data.rename to rename some value of index or columns\n",
    "data.rename(columns={'ONE':'OnE','THREE':'Three'},index={'Ohio':'OhiO','New York':'NewYork'},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discretization and Binning\n",
    "###### Category type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    250\n",
       "b    250\n",
       "c    250\n",
       "d    250\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# discretized is cut the value for the each of range of value\n",
    "# create a series of numeric value\n",
    "num=[10,20,30,40,50,19,18,2,-3,-10]\n",
    "# check the min max to cut the range\n",
    "min(num);max(num)# min=-10, max=50\n",
    "# creat a range list\n",
    "bins=[-20,0,20,40,60]# create 4 category class\n",
    "# put each value of num to range that be created by bins\n",
    "cats=pd.cut(x=num,bins=bins)# Categorical object type\n",
    "# count the number of categories \n",
    "cats.value_counts()\n",
    "# check the position of bins\n",
    "cats.codes\n",
    "# check the categories\n",
    "cats.categories\n",
    "# put the label name for each categories\n",
    "cats=pd.cut(x=num,bins=bins,labels=['one','two','three','four'])\n",
    "# give the precision for the decimal number and auto divide the categories\n",
    "data=np.random.randn(20)\n",
    "# pass the number for bins and the name for the label name\n",
    "cats=pd.cut(x=data,bins=5,precision=3,labels=list('abcde'))\n",
    "cats\n",
    "#-------------------------------------------------------\n",
    "# Use qcut to get each categories that has the same quantile value\n",
    "# create an array that contains 1000 value \n",
    "data=np.random.randn(1000)\n",
    "# divide to 4 categories and put the name for each categories.Then test the value counts of each categories\n",
    "pd.qcut(x=data,q=4,labels=list('abcd'),precision=2).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecting and Filtering Outliers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>499</td>\n",
       "      <td>397</td>\n",
       "      <td>993</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>-898</td>\n",
       "      <td>1000</td>\n",
       "      <td>509</td>\n",
       "      <td>405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>-994</td>\n",
       "      <td>524</td>\n",
       "      <td>735</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>740</td>\n",
       "      <td>-131</td>\n",
       "      <td>995</td>\n",
       "      <td>-351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>302</td>\n",
       "      <td>-252</td>\n",
       "      <td>997</td>\n",
       "      <td>812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>236</td>\n",
       "      <td>417</td>\n",
       "      <td>996</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>1000</td>\n",
       "      <td>-90</td>\n",
       "      <td>-920</td>\n",
       "      <td>-254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>-224</td>\n",
       "      <td>996</td>\n",
       "      <td>544</td>\n",
       "      <td>860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>966</th>\n",
       "      <td>994</td>\n",
       "      <td>533</td>\n",
       "      <td>723</td>\n",
       "      <td>-448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>994</td>\n",
       "      <td>-264</td>\n",
       "      <td>-664</td>\n",
       "      <td>-439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        A     B    C    D\n",
       "58    499   397  993  225\n",
       "76   -898  1000  509  405\n",
       "101  -994   524  735  999\n",
       "112   740  -131  995 -351\n",
       "139   302  -252  997  812\n",
       "..    ...   ...  ...  ...\n",
       "882   236   417  996  245\n",
       "925  1000   -90 -920 -254\n",
       "957  -224   996  544  860\n",
       "966   994   533  723 -448\n",
       "988   994  -264 -664 -439\n",
       "\n",
       "[29 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a df with 4000 value randint(1,1000)\n",
    "data=pd.DataFrame(data=np.array([random.randint(-1000,1000) for x in range(4000)]).reshape(1000,4),columns=list('ABCD'),dtype=np.int64)\n",
    "# give the descriptive about the df\n",
    "data.describe()\n",
    "# choose the columns ('A','B','C') that have the |value of 'B'|>900 \n",
    "abs1=data[['A','B','C']][np.abs(data['B'])>900]\n",
    "# pick the data that have at least |data|>990 apeeared any each row (~axis=1)\n",
    "abs2=data[(np.abs(data)>990).any(axis=1)]\n",
    "# another way to pick the value |data|>990 is use sign(x)*n\n",
    "# create the data that only contain only value (990,-990)\n",
    "sign=np.sign(data)*990# np.sign return the value positive(1) and negative(-1)\n",
    "# choose the row that has at least value of data> |sign|\n",
    "data[(data>np.abs(sign)).any(1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permutation and Random Sampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5</th>\n",
       "      <th>7</th>\n",
       "      <th>4</th>\n",
       "      <th>16</th>\n",
       "      <th>19</th>\n",
       "      <th>...</th>\n",
       "      <th>14</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-9</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>-5</td>\n",
       "      <td>-3</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>-3</td>\n",
       "      <td>-6</td>\n",
       "      <td>-8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>-10</td>\n",
       "      <td>...</td>\n",
       "      <td>-3</td>\n",
       "      <td>-10</td>\n",
       "      <td>-7</td>\n",
       "      <td>-10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-7</td>\n",
       "      <td>1</td>\n",
       "      <td>-3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>-2</td>\n",
       "      <td>-3</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>-7</td>\n",
       "      <td>-9</td>\n",
       "      <td>-6</td>\n",
       "      <td>-8</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-4</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-2</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>-8</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-7</td>\n",
       "      <td>4</td>\n",
       "      <td>-4</td>\n",
       "      <td>6</td>\n",
       "      <td>-6</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>-5</td>\n",
       "      <td>7</td>\n",
       "      <td>-5</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-5</td>\n",
       "      <td>1</td>\n",
       "      <td>-9</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-9</td>\n",
       "      <td>8</td>\n",
       "      <td>-2</td>\n",
       "      <td>-7</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-7</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>7</td>\n",
       "      <td>-8</td>\n",
       "      <td>-8</td>\n",
       "      <td>8</td>\n",
       "      <td>-9</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    5   7   4   16  19 ...  14  8   9   10  0 \n",
       "0   -9   3   3  -5  -3 ...   7  -3  -6  -8   3\n",
       "1    2  10   6   3 -10 ...  -3 -10  -7 -10   3\n",
       "2    0  -1  -7   1  -3 ...   1   5   2   8   6\n",
       "3    2   4   0   4   8 ...   6  -2  -3  10   4\n",
       "4    3  -7  -9  -6  -8 ...   1  -4   9   5 -10\n",
       "..  ..  ..  ..  ..  .. ...  ..  ..  ..  ..  ..\n",
       "15  -2   8  10   6  -8 ...   1   0  -5   1   8\n",
       "16  -7   4  -4   6  -6 ...   8  -5   7  -5  -2\n",
       "17  -4  -4  -5   1  -9 ...   6  10   7   1   4\n",
       "18  -9   8  -2  -7   9 ...   0  -7   0   5   2\n",
       "19   7  -8  -8   8  -9 ...  -1   7   7   7   7\n",
       "\n",
       "[20 rows x 20 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create df (20,20)\n",
    "data=pd.DataFrame(data=np.array([random.randint(-10,10) for x in range(400)]).reshape(20,20))\n",
    "# create the permutation by random the sequence of col or row and then assign it\n",
    "data.reindex(columns=np.random.permutation(20),index=np.random.permutation(20))\n",
    "# we can create a new sequence for permutation\n",
    "permu=np.random.permutation(20)\n",
    "# let the df take the permu for axis=1\n",
    "data.take(permu,axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing Indicator/Dummy Variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create a df having shape(12,4)\n",
    "df=pd.DataFrame({'key':['a','b','c',NA]*3,\n",
    "                'value':['apple','banana','coconut',NA]*3,\n",
    "                'numth':[x for x in range(0,12)]})\n",
    "# dummies the distinct value of df['key'] and convert to 0s and 1s\n",
    "key_dummies=pd.get_dummies(data=df['key'],prefix='key',dummy_na=True) # 1 is True and 0 is False\n",
    "value_dummies=pd.get_dummies(data=df['value'],prefix='value',dummy_na=True)\n",
    "numth_dummies=pd.get_dummies(data=df['numth'],prefix='numth',dummy_na=True)\n",
    "# join df with key-value_ dummies\n",
    "df_dummies=df[['numth']].join([key_dummies,value_dummies])\n",
    "# choose the df_dummies where the key_a appeared and numth==4\n",
    "df_dummies[((df_dummies['key_a']==1)&(df_dummies['numth']==4))]\n",
    "#-------------------------------------------\n",
    "# read the file movies.dat\n",
    "f=open('Pydata-book/pydata-book-2nd-edition/datasets/movielens/movies.dat')\n",
    "# read file 'f' with names,sep, and engine='python' to deal with 'sep' has 2 character\n",
    "movie=pd.read_table(f,sep='::',header=None,names=['movie_id','title','genres'],engine='python')\n",
    "# Apply function to split on movie['genres']\n",
    "genres=list(movie['genres'].apply(lambda x: x.split('|')))\n",
    "# add every element the movie['genres'] having to the list\n",
    "all_genres=[]\n",
    "for x in genres:\n",
    "    if x not in all_genres:\n",
    "        all_genres.extend(x)\n",
    "    else:\n",
    "        continue\n",
    "# take the set unique of list \n",
    "unique=set(all_genres)\n",
    "# create the matrix with shape(len(movie),len(unique)) to join with the df movie\n",
    "zero_matrix=np.zeros((len(movie),len(unique)))# shape(3882,18)\n",
    "# put the name for the  zero_matrix\n",
    "dummies=pd.DataFrame(zero_matrix,columns=unique)\n",
    "# manually change the value 0s,1s in the dummies\n",
    "for i,gen in enumerate(movie.genres):\n",
    "    # get the index list and use it to change the value 1 at each position\n",
    "    indices=dummies.columns.get_indexer(gen.split('|'))\n",
    "    # choose the location of df and change it\n",
    "    dummies.iloc[i,indices]=1\n",
    "# join the df 'movie' with the dummies with the same index\n",
    "movie_windic=movie.join(dummies.add_prefix('Genre_'))\n",
    "movie_windic.iloc[0]\n",
    "#-------------------------------------------------\n",
    "# Combine the pd.cut and pd.get_dummies\n",
    "data=pd.DataFrame({'a':[random.randint(1,100) for x in range(10)],\n",
    "                   'b':[random.randint(1,100) for x in range(10)]})\n",
    "lst_range=[20,30,50,70,90,100]\n",
    "# cut categories for each columns of df\n",
    "for i in data.columns:# consider each name of col\n",
    "    # change the original df \n",
    "    data[i]=pd.cut(x=data[i],bins=lst_range,labels=['one','two','three','four','five'])\n",
    "# Get the dummies the each value of each columns\n",
    "dummies_cut=pd.get_dummies(data=data,columns=['a','b'],prefix='col',dummy_na=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.3 String Manipulation\n",
    "### String Object Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a:b:geníous,'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# given the string\n",
    "val=' a ,b ,  geníous,  '\n",
    "# separate the string to list with max split\n",
    "lst_val=val.split(sep=',',maxsplit=2)\n",
    "# strip each element in lst_val\n",
    "lst_strip=[x.strip() for x in lst_val]\n",
    "# check the exist substring in string\n",
    "',' in val\n",
    "# return the first index of substring appeared( can raise the error if not existed)\n",
    "val.index(',')\n",
    "# find the position of index (return -1 if no result)\n",
    "val.find(', ')# ~val.index()\n",
    "# replace the substring\n",
    "val.replace(',','?')\n",
    "# use lower,upper,title,capitalize\n",
    "val.capitalize()\n",
    "# check the number of string ','\n",
    "count=val.count(',')\n",
    "# unpack the list as 3 string\n",
    "first,second,third=lst_strip\n",
    "# concanate 3 string with each sep=':'\n",
    "first+':'+second+':'+third\n",
    "# join can be used to concanate string\n",
    "':'.join(lst_strip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regular Expressions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text='::ngoc::thach::son,the,thach'\n",
    "# compile the string to the pattern can be used as a regex (~ a single expression)\n",
    "regex=re.compile(pattern='::')\n",
    "regex1=re.compile(pattern=',')\n",
    "# spliit the text with pattern_sep=regex\n",
    "regex.split(text)\n",
    "# continue split the string that dont have anymore '::' pattern\n",
    "regex1.split(','.join(regex.split(text)))# use join to concanate element of list to one string\n",
    "# compile to more pattern in one expression\n",
    "regex2=re.compile(pattern='{0}|{1}'.format('::',','))# return the pattern is '::' or','\n",
    "regex2.split(text)# unpack every element in text\n",
    "regex2.findall(text)# return the list of regex2 is used to split text\n",
    "# return the first position of the first pattern appeared in strinng\n",
    "regex2.match(text)# only use matches at the beginning of string\n",
    "regex2.search(text)# return the span of the first pattern appeared\n",
    "#----------------------------------------------------------------\n",
    "#Create the complex pattern of string having some special character[$#@,.+]\n",
    "email='''\n",
    "Ngoc dinhthengoc2021998$gmail,comde\n",
    "Ngoc1 dinhthengoc1998@yahoo.com\n",
    "thach dinhthethach4994#google+com\n",
    "'''\n",
    "# [A-Z0-9] means to the string that have letter or digit from[0-9]\n",
    "# [@$#] accept the string that have one character is in [@] or [$] or [#]\n",
    "# {2-4} is the chunksize for the chardter [A-Z]\n",
    "pattern='[A-Z0-9]+[@$#][A-Z0-9]+[.,+][A-Z]{2,4}'\n",
    "# assign the complex pattern to regex3 without care about lower,upper,.. CASE\n",
    "regex3=re.compile(pattern=pattern,flags=re.IGNORECASE)\n",
    "# findall and take list of string that has the same pattern with the regex\n",
    "regex3.findall(email)\n",
    "# search the span of the pattern that firstly appeared \n",
    "search=regex3.search(email)\n",
    "# take the string of the first string that have the same pattern\n",
    "search.start()# return the start position of string 'search'\n",
    "search.end()# return the end position of string 'search'\n",
    "email[search.start():search.end()]# extract the substring from start:end of string'search'\n",
    "# replace the substring that having the complex pattern\n",
    "new_email=regex3.sub(repl='Nothing',string=email)\n",
    "#---------------------------------------------------------------\n",
    "# unpack the email to 3 component is username,domain name,domain suffix\n",
    "# put parentheses to each position to put the parentheses pattern to one string\n",
    "# ([A-Z]{0,3}) is one string with pattern character capitalize from{0,3}\n",
    "new_pattern='([A-Z0-9._]+)[@#$]([A-Z0-9]+)[,.+]([A-Z]{0,3})'\n",
    "new_regex=re.compile(pattern=new_pattern,flags=re.IGNORECASE)\n",
    "unpack_email=new_regex.findall(email)\n",
    "#---------------------------------------------------------\n",
    "# create the empty list of user, domain_name,domain_suffix \n",
    "user,domain_name,domain_suffix=[],[],[]\n",
    "# append each value to correspondence list\n",
    "for x in unpack_email:# consider each tuple in list\n",
    "    for i,m in enumerate([user,domain_name,domain_suffix]):# do with each empty list\n",
    "        m.append(x[i])# append string of each tuple in list\n",
    "# create an empty dataframe with name of col,index\n",
    "df=pd.DataFrame(columns=['user','domain_name','domain_suffix'],index=range(len(user)))\n",
    "# add value of columns as list \n",
    "lst_columns=[user,domain_name,domain_suffix]\n",
    "for i,m in enumerate(lst_columns):\n",
    "    df.iloc[:,i]=m # subset each columns=list\n",
    "#--------------------------------------------------------\n",
    "# use dictionary to create df1\n",
    "df1=pd.DataFrame(data={'user':user,'domain_name':domain_name,'domain_suffix':domain_suffix},\n",
    "                 columns=['user','domain_name','domain_suffix'],\n",
    "                 index=range(len(user)))\n",
    "#--------------------------------------------------------\n",
    "# build the data as a nested list then assign to df\n",
    "[list(x) for x in list(zip(user,domain_name,domain_suffix))]# [list(x)]\n",
    "df=pd.DataFrame(data=[list(x) for x in list(zip(user,domain_name,domain_suffix))],\n",
    "                     columns=['user','domain_name','domain_suffix'],\n",
    "                 index=range(len(user)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorized String Functions in pandas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>name matches</th>\n",
       "      <th>user</th>\n",
       "      <th>domain_name</th>\n",
       "      <th>domain_suffix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dave</th>\n",
       "      <td>dave@google.comasd</td>\n",
       "      <td>dave@google.com</td>\n",
       "      <td>dave</td>\n",
       "      <td>google</td>\n",
       "      <td>com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rob</th>\n",
       "      <td>rob@gmail.com</td>\n",
       "      <td>rob@gmail.com</td>\n",
       "      <td>rob</td>\n",
       "      <td>gmail</td>\n",
       "      <td>com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Steve</th>\n",
       "      <td>steve@gmail.com</td>\n",
       "      <td>steve@gmail.com</td>\n",
       "      <td>steve</td>\n",
       "      <td>gmail</td>\n",
       "      <td>com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wes</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     name     name matches   user domain_name domain_suffix\n",
       "Dave   dave@google.comasd  dave@google.com   dave      google           com\n",
       "Rob         rob@gmail.com    rob@gmail.com    rob       gmail           com\n",
       "Steve     steve@gmail.com  steve@gmail.com  steve       gmail           com\n",
       "Wes                   NaN              NaN    NaN         NaN           NaN"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {'Dave': 'dave@google.com','Steve': 'steve@gmail.com',\n",
    "        'Rob': 'rob@gmail.com', 'Wes': NA}\n",
    "df=pd.DataFrame(data={'name':{'Dave': 'dave@google.comasd','Steve': 'steve@gmail.com',\n",
    "                    'Rob': 'rob@gmail.com', 'Wes': NA}})\n",
    "# create a regex with a pattern to split string\n",
    "pattern='([A-Z0-9._]+)[@]([A-Z0-9._]+)[.]([A-Z]{0,3})'\n",
    "regex=re.compile(pattern=pattern,flags=re.IGNORECASE)\n",
    "# choose the row that df['name'] has 'gmail' in string\n",
    "df[df['name'].apply(lambda x: 'gmail' in str(x))]\n",
    "# choose the row has df['name'] is NA\n",
    "df[df['name'].map(lambda x: x is NA)]\n",
    "# apply function (plit string) for df['name']\n",
    "df['name'].apply(lambda x: regex.findall(str(x)))\n",
    "# check the pattern in df['name']\n",
    "matches=df['name'].apply(lambda x: regex.search(str(x)))# type series\n",
    "# create new columns to take the string corresponding with pattern\n",
    "df=df.join(matches,rsuffix=' matches')\n",
    "# change value of 'name matches' with the same index\n",
    "for i in range(len(df.index)):\n",
    "    if df.iloc[i,0] is not NA:\n",
    "        df.iloc[i,1]=(df.iloc[i,0])[matches[i].start():matches[i].end()]\n",
    "    else: \n",
    "        df.iloc[i,1]=NA\n",
    "#----------------------------------------------------------\n",
    "# unpack the [user,domain_name,domain_suffix]then join with df \n",
    "new_df=df.join(pd.DataFrame(columns=['user','domain_name','domain_suffix'],index=df.index))\n",
    "# choose a notnull df because can unpack NA value\n",
    "notnull=new_df[new_df['name'].notnull()]\n",
    "# apply regex to find all string that have the same pattern for each group()\n",
    "unpack=notnull['name matches'].apply(lambda x: regex.findall(str(x)))\n",
    "# create data for value of df['user','domain_name','domain_suffix']\n",
    "data=[]\n",
    "for i,x in enumerate(unpack):\n",
    "    # change type of each unpack to list, not list of tuple\n",
    "    unpack[i]=list(x[0])\n",
    "    # add value to data\n",
    "    data.append(unpack[i])\n",
    "# join df with df['user','domain_name','domain_suffix']  \n",
    "new_df=df.join(pd.DataFrame(data=data,columns=['user','domain_name','domain_suffix'],index=notnull.index))\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
